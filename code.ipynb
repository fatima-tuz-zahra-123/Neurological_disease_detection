{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15af0bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in testing folder: 84825\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "total_images = 0\n",
    "base_dir = r\"/Users/fatimatuzzahra/Downloads/processed_slices/train\"\n",
    "\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.png'):\n",
    "            total_images += 1\n",
    "\n",
    "print(\"Total images in testing folder:\", total_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1309767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import clip\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33933561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD axial images: 17575\n",
      "CN axial images: 25795\n",
      "MCI axial images: 41455\n",
      "Total axial images: 84825\n"
     ]
    }
   ],
   "source": [
    "base_dir = r\"/Users/fatimatuzzahra/Downloads/processed_slices/train\"\n",
    "class_names = ['AD', 'CN', 'MCI']\n",
    "total_images = 0\n",
    "\n",
    "for class_name in class_names:\n",
    "    path = os.path.join(base_dir, class_name, 'axial')\n",
    "    if os.path.exists(path):\n",
    "        num_files = len([f for f in os.listdir(path) if f.lower().endswith('.png')])\n",
    "        print(f\"{class_name} axial images: {num_files}\")\n",
    "        total_images += num_files\n",
    "    else:\n",
    "        print(f\" Path not found: {path}\")\n",
    "\n",
    "print(\"Total axial images:\", total_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "992716d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing AD: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17575/17575 [18:58<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CN: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25795/25795 [3:27:01<00:00,  2.08it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing MCI: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41455/41455 [55:53<00:00, 12.36it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors saved:\n",
      "train_features_axial.npy\n",
      "train_labels_axial.npy\n",
      "train_image_paths_axial.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import imgaug.augmenters as iaa\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "# from tensorflow.keras.applications import DenseNet121.  # densenet code\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Extracting CLIP Image features\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess_clip = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Define your own compatible augmentations\n",
    "augmenter = T.Compose([\n",
    "    T.Resize(224),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(10),\n",
    "    T.GaussianBlur(kernel_size=3),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))  # CLIP normalization\n",
    "])\n",
    "\n",
    "# EfficientNet base model\n",
    "# base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "# # Step 3: Build feature extractor model (outputs 256-dim feature vectors)\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "# feature_extractor = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Step 4: Setup paths and label mapping\n",
    "base_dir = r\"/Users/fatimatuzzahra/Downloads/processed_slices/train\"\n",
    "classes = ['AD', 'CN', 'MCI']\n",
    "label_map = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "features, labels, image_paths = [], [], []\n",
    "\n",
    "# Step 5: Loop through dataset and extract features\n",
    "for cls in classes:\n",
    "    print(cls)\n",
    "    class_dir = os.path.join(base_dir, cls, 'axial')\n",
    "    if not os.path.exists(class_dir):\n",
    "        print(f\"Directory not found: {class_dir}\")\n",
    "        continue\n",
    "\n",
    "    for fname in tqdm(os.listdir(class_dir), desc=f\"Processing {cls}\"):\n",
    "        if fname.lower().endswith('.png'):\n",
    "            img_path = os.path.join(class_dir, fname)\n",
    "            try:\n",
    "                pil_img = Image.open(img_path).convert(\"RGB\")\n",
    "                \n",
    "                # --------- Original Image ---------\n",
    "                orig_img = preprocess_clip(pil_img).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    orig_feat = model.encode_image(orig_img).cpu().numpy().flatten()\n",
    "                features.append(orig_feat)\n",
    "                labels.append(label_map[cls])\n",
    "                image_paths.append(img_path)\n",
    "\n",
    "                # --------- Augmented Image ---------\n",
    "                aug_img_tensor = augmenter(pil_img).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    aug_feat = model.encode_image(aug_img_tensor).cpu().numpy().flatten()\n",
    "                features.append(aug_feat)\n",
    "                labels.append(label_map[cls])\n",
    "                image_paths.append(img_path + \"_aug\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {img_path}: {e}\")\n",
    "\n",
    "# Step 6: Save features, labels, and paths\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "image_paths = np.array(image_paths)\n",
    "\n",
    "np.save(\"train_features_axial.npy\", features)\n",
    "np.save(\"train_labels_axial.npy\", labels)\n",
    "np.save(\"train_image_paths_axial.npy\", image_paths)\n",
    "\n",
    "print(\"Feature vectors saved:\")\n",
    "print(\"train_features_axial.npy\")\n",
    "print(\"train_labels_axial.npy\")\n",
    "print(\"train_image_paths_axial.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803ce3e5",
   "metadata": {},
   "source": [
    "same process as above for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75cb0718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing AD: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1870/1870 [00:57<00:00, 32.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CN: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2585/2585 [01:20<00:00, 32.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing MCI: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3960/3960 [02:03<00:00, 32.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors saved:\n",
      "val_features_axial.npy\n",
      "val_labels_axial.npy\n",
      "val_image_paths_axial.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import imgaug.augmenters as iaa\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "# from tensorflow.keras.applications import DenseNet121.  # densenet code\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Extracting CLIP Image features\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess_clip = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Define your own compatible augmentations\n",
    "augmenter = T.Compose([\n",
    "    T.Resize(224),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(10),\n",
    "    T.GaussianBlur(kernel_size=3),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))  # CLIP normalization\n",
    "])\n",
    "\n",
    "\n",
    "# EfficientNet ase model\n",
    "# base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "# # Step 3: Build feature extractor model (outputs 256-dim feature vectors)\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "# feature_extractor = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Step 4: Setup paths and label mapping\n",
    "base_dir = r\"/Users/fatimatuzzahra/Downloads/processed_slices/val\"\n",
    "classes = ['AD', 'CN', 'MCI']\n",
    "label_map = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "features, labels, image_paths = [], [], []\n",
    "\n",
    "# Step 5: Loop through dataset and extract features\n",
    "for cls in classes:\n",
    "    print(cls)\n",
    "    class_dir = os.path.join(base_dir, cls, 'axial')\n",
    "    if not os.path.exists(class_dir):\n",
    "        print(f\"Directory not found: {class_dir}\")\n",
    "        continue\n",
    "\n",
    "    for fname in tqdm(os.listdir(class_dir), desc=f\"Processing {cls}\"):\n",
    "        if fname.lower().endswith('.png'):\n",
    "            img_path = os.path.join(class_dir, fname)\n",
    "            try:\n",
    "                img = preprocess_clip(Image.open(img_path)).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    feat = model.encode_image(img)\n",
    "                    feat = feat.cpu().numpy().flatten()\n",
    "                features.append(feat)\n",
    "                labels.append(label_map[cls])\n",
    "                image_paths.append(img_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed: {img_path}, {e}\")\n",
    "\n",
    "# Step 6: Save features, labels, and paths\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "image_paths = np.array(image_paths)\n",
    "\n",
    "np.save(\"val_features_axial.npy\", features)\n",
    "np.save(\"val_labels_axial.npy\", labels)\n",
    "np.save(\"val_image_paths_axial.npy\", image_paths)\n",
    "\n",
    "print(\"Feature vectors saved:\")\n",
    "print(\"val_features_axial.npy\")\n",
    "print(\"val_labels_axial.npy\")\n",
    "print(\"val_image_paths_axial.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d7369c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169650, 512)\n",
      "(169650,)\n",
      "(169650,)\n"
     ]
    }
   ],
   "source": [
    "features = np.load(\"train_features_axial.npy\")       # Shape: (84755, 256)\n",
    "print(features.shape)\n",
    "labels = np.load(\"train_labels_axial.npy\")           # Shape: (84755,)\n",
    "print(labels.shape)\n",
    "image_paths = np.load(\"train_image_paths_axial.npy\") # Shape: (84755,)\n",
    "print(image_paths.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bd24bc",
   "metadata": {},
   "source": [
    "loading and printing features and other things for validation data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b05433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8415, 512)\n",
      "(8415,)\n",
      "(8415,)\n"
     ]
    }
   ],
   "source": [
    "features = np.load(\"val_features_axial.npy\")       # Shape: (84755, 256)\n",
    "print(features.shape)\n",
    "labels = np.load(\"val_labels_axial.npy\")           # Shape: (84755,)\n",
    "print(labels.shape)\n",
    "image_paths = np.load(\"val_image_paths_axial.npy\") # Shape: (84755,)\n",
    "print(image_paths.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17262be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved: train_axial_features_and_labels_only.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the .npy files\n",
    "import pandas as pd\n",
    "features = np.load(\"train_features_axial.npy\")       # Shape: (84755, 256)\n",
    "labels = np.load(\"train_labels_axial.npy\")           # Shape: (84755,)\n",
    "\n",
    "# Combine features and labels\n",
    "combined = np.hstack((features, labels.reshape(-1, 1)))  # Shape: (84755, 257)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(combined)\n",
    "\n",
    "# Optionally name columns\n",
    "\n",
    "feature_columns = [f\"f{i}\" for i in range(features.shape[1])]\n",
    "df.columns = feature_columns + [\"label\"]\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"train_axial_features_and_labels_only.csv\", index=False)\n",
    "\n",
    "print(\" Saved: train_axial_features_and_labels_only.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8f8f1",
   "metadata": {},
   "source": [
    "same process for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9af99964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved: val_axial_features_and_labels_only.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the .npy files\n",
    "features = np.load(\"val_features_axial.npy\")       # Shape: (84755, 256)\n",
    "labels = np.load(\"val_labels_axial.npy\")           # Shape: (84755,)\n",
    "\n",
    "# Combine features and labels\n",
    "combined = np.hstack((features, labels.reshape(-1, 1)))  # Shape: (84755, 257)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(combined)\n",
    "\n",
    "# Optionally name columns\n",
    "feature_columns = [f\"f{i}\" for i in range(features.shape[1])]\n",
    "df.columns = feature_columns + [\"label\"]\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"val_axial_features_and_labels_only.csv\", index=False)\n",
    "\n",
    "print(\" Saved: val_axial_features_and_labels_only.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "917722db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 169650/169650 [00:00<00:00, 373353.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Matched samples: 169650\n",
      " Final train fused shape: (169650, 1024)\n",
      " Labels shape: (169650,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Load image feature data\n",
    "image_features = np.load(\"train_features_axial.npy\")       # (84755, 256)\n",
    "image_labels = np.load(\"train_labels_axial.npy\")           # (84755,)\n",
    "image_paths = np.load(\"train_image_paths_axial.npy\")       # (84755,)\n",
    "\n",
    "# Load cleaned textual embeddings and IDs\n",
    "textual_embeddings = np.load(\"text_embeddings_cleaned.npy\")   # (2294, 384)\n",
    "text_ids = np.load(\"text_image_ids.npy\", allow_pickle=True)      # (2294,)\n",
    "\n",
    "# Step 1: Build a lookup from Image ID â†’ text embedding\n",
    "text_lookup = {id_: emb for id_, emb in zip(text_ids, textual_embeddings)}\n",
    "\n",
    "# Step 2: Match each image with its text embedding (based on ID prefix)\n",
    "fused_features = []\n",
    "fused_labels = []\n",
    "matched_count = 0\n",
    "\n",
    "for i, (img_feat, label, path) in enumerate(tqdm(zip(image_features, image_labels, image_paths), total=len(image_paths))):\n",
    "    filename = os.path.basename(path)  # e.g., 'I31143_AD_axial_55.png'\n",
    "    img_id = filename.split('_')[0]             # 'I31143'\n",
    "\n",
    "    if img_id in text_lookup:\n",
    "        text_feat = text_lookup[img_id]\n",
    "        fused = np.concatenate([img_feat, text_feat])  # shape (640,)\n",
    "        fused_features.append(fused)\n",
    "        fused_labels.append(label)\n",
    "        matched_count += 1\n",
    "\n",
    "print(f\" Matched samples: {matched_count}\")\n",
    "\n",
    "# Convert to arrays and save\n",
    "fused_features = np.array(fused_features)\n",
    "fused_labels = np.array(fused_labels)\n",
    "\n",
    "np.save(\"train_fused_features_clean.npy\", fused_features)\n",
    "np.save(\"train_fused_labels_clean.npy\", fused_labels)\n",
    "\n",
    "print(\" Final train fused shape:\", fused_features.shape)\n",
    "print(\" Labels shape:\", fused_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05348e3",
   "metadata": {},
   "source": [
    "fusion for the validation set is done below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "672a555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8415/8415 [00:00<00:00, 138712.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Matched samples: 8415\n",
      " Final val fused shape: (8415, 1024)\n",
      " Labels shape: (8415,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Load image feature data\n",
    "image_features = np.load(\"val_features_axial.npy\")       # (84755, 256)\n",
    "image_labels = np.load(\"val_labels_axial.npy\")           # (84755,)\n",
    "image_paths = np.load(\"val_image_paths_axial.npy\")       # (84755,)\n",
    "\n",
    "# Load cleaned textual embeddings and IDs\n",
    "textual_embeddings = np.load(\"text_embeddings_cleaned.npy\")   # (2294, 384)\n",
    "text_ids = np.load(\"text_image_ids.npy\", allow_pickle=True)      # (2294,)\n",
    "\n",
    "# Step 1: Build a lookup from Image ID â†’ text embedding\n",
    "text_lookup = {id_: emb for id_, emb in zip(text_ids, textual_embeddings)}\n",
    "\n",
    "# Step 2: Match each image with its text embedding (based on ID prefix)\n",
    "fused_features = []\n",
    "fused_labels = []\n",
    "matched_count = 0\n",
    "\n",
    "for i, (img_feat, label, path) in enumerate(tqdm(zip(image_features, image_labels, image_paths), total=len(image_paths))):\n",
    "    filename = os.path.basename(path)  # e.g., 'I31143_AD_axial_55.png'\n",
    "    img_id = filename.split('_')[0]             # 'I31143'\n",
    "\n",
    "    if img_id in text_lookup:\n",
    "        text_feat = text_lookup[img_id]\n",
    "        fused = np.concatenate([img_feat, text_feat])  # shape (640,)\n",
    "        fused_features.append(fused)\n",
    "        fused_labels.append(label)\n",
    "        matched_count += 1\n",
    "\n",
    "print(f\" Matched samples: {matched_count}\")\n",
    "\n",
    "# Convert to arrays and save\n",
    "fused_features = np.array(fused_features)\n",
    "fused_labels = np.array(fused_labels)\n",
    "\n",
    "np.save(\"val_fused_features_clean.npy\", fused_features)\n",
    "np.save(\"val_fused_labels_clean.npy\", fused_labels)\n",
    "\n",
    "print(\" Final val fused shape:\", fused_features.shape)\n",
    "print(\" Labels shape:\", fused_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b11ac337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved: train_fused_embeddings_with_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load\n",
    "X = np.load(\"train_fused_features_clean.npy\")\n",
    "y = np.load(\"train_fused_labels_clean.npy\")\n",
    "\n",
    "# Combine into DataFrame\n",
    "df = pd.DataFrame(X)\n",
    "df[\"label\"] = y\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"train_fused_embeddings_with_labels.csv\", index=False)\n",
    "print(\" Saved: train_fused_embeddings_with_labels.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c2db0",
   "metadata": {},
   "source": [
    "savinf into csv the validation fused sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "886ef189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved: val_fused_embeddings_with_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load\n",
    "X = np.load(\"val_fused_features_clean.npy\")\n",
    "y = np.load(\"val_fused_labels_clean.npy\")\n",
    "\n",
    "# Combine into DataFrame\n",
    "df = pd.DataFrame(X)\n",
    "df[\"label\"] = y\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"val_fused_embeddings_with_labels.csv\", index=False)\n",
    "print(\" Saved: val_fused_embeddings_with_labels.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50158e89",
   "metadata": {},
   "source": [
    "saving image and textual data separately for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "315c40f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved:\n",
      "  train_image_features_only.npy (shape: (169650, 256) )\n",
      "  train_text_features_only.npy  (shape: (169650, 768) )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load fused embeddings\n",
    "fused = np.load(\"train_fused_features_clean.npy\")  # (84755, 640)\n",
    "\n",
    "# Split features\n",
    "image_features = fused[:, :256]   # CNN-based\n",
    "text_features  = fused[:, 256:]   # Sentence-transformer-based\n",
    "\n",
    "# Save separately\n",
    "np.save(\"train_image_features_only.npy\", image_features)\n",
    "np.save(\"train_text_features_only.npy\", text_features)\n",
    "\n",
    "print(\" Saved:\")\n",
    "print(\"  train_image_features_only.npy (shape:\", image_features.shape, \")\")\n",
    "print(\"  train_text_features_only.npy  (shape:\", text_features.shape, \")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1136a005",
   "metadata": {},
   "source": [
    "saving image and textual data separately for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e6e17f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved:\n",
      "  val_image_features_only.npy (shape: (8415, 256) )\n",
      "  val_text_features_only.npy  (shape: (8415, 768) )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load fused embeddings\n",
    "fused = np.load(\"val_fused_features_clean.npy\")  # (84755, 640)\n",
    "\n",
    "# Split features\n",
    "image_features = fused[:, :256]   # CNN-based\n",
    "text_features  = fused[:, 256:]   # Sentence-transformer-based\n",
    "\n",
    "# Save separately\n",
    "np.save(\"val_image_features_only.npy\", image_features)\n",
    "np.save(\"val_text_features_only.npy\", text_features)\n",
    "\n",
    "print(\" Saved:\")\n",
    "print(\"  val_image_features_only.npy (shape:\", image_features.shape, \")\")\n",
    "print(\"  val_text_features_only.npy  (shape:\", text_features.shape, \")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33f960",
   "metadata": {},
   "source": [
    "the code below is added just to save the progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f29456",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ðŸ”¹ Step 1: Load training set fused features and labels\n",
    "X_train = np.load(\"train_fused_features_clean.npy\")   # Shape: (84755, 640)\n",
    "y_train = np.load(\"train_fused_labels_clean.npy\")     # Shape: (84755,)\n",
    "\n",
    "# Step 2: Load validation set fused features and labels\n",
    "X_val = np.load(\"val_fused_features_clean.npy\")\n",
    "y_val = np.load(\"val_fused_labels_clean.npy\")\n",
    "\n",
    "# ðŸ”¹ Step 2: Train/test split (not used for testing file)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "\n",
    "# ðŸ”¹ Step 3: Define and train MLP (no need of fitting again in test set)\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(512, 256, 64),   # You can adjust the architecture\n",
    "    activation='relu',\n",
    "    learning_rate_init=0.0006,\n",
    "    solver='adam',\n",
    "    max_iter=50,          # Increase to 100â€“300 for better results if time allows\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# ðŸ”¹ Step 4: Predict and evaluate\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n MLP Accuracy: {acc:.4f}\")\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"AD\", \"CN\", \"MCI\"]))\n",
    "\n",
    "# ðŸ”¹ Step 5: Plot Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=[\"AD\", \"CN\", \"MCI\"], yticklabels=[\"AD\", \"CN\", \"MCI\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\" Confusion Matrix - MLP (Fused Features)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd979ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPWithDropout(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPWithDropout, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Example usage:\n",
    "input_dim = X_train.shape[1]\n",
    "model = MLPWithDropout(input_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1daffc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.0670\n",
      "Epoch 2/10, Loss: 1.0227\n",
      "Epoch 3/10, Loss: 0.9895\n",
      "Epoch 4/10, Loss: 0.9637\n",
      "Epoch 5/10, Loss: 0.9403\n",
      "Epoch 6/10, Loss: 0.9218\n",
      "Epoch 7/10, Loss: 0.9038\n",
      "Epoch 8/10, Loss: 0.8879\n",
      "Epoch 9/10, Loss: 0.8725\n",
      "Epoch 10/10, Loss: 0.8586\n",
      "ðŸ“Š Training Accuracy: 0.6616\n",
      "âœ… Validation Accuracy: 0.4935\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.39      0.47      0.42      1870\n",
      "          CN       0.46      0.39      0.42      2585\n",
      "         MCI       0.57      0.58      0.57      3960\n",
      "\n",
      "    accuracy                           0.49      8415\n",
      "   macro avg       0.47      0.48      0.47      8415\n",
      "weighted avg       0.50      0.49      0.49      8415\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import torch.nn as nn\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torch \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "X_train = np.load(\"train_image_features_only.npy\")\n",
    "y_train = np.load(\"train_fused_labels_clean.npy\")\n",
    "X_val = np.load(\"val_image_features_only.npy\")\n",
    "y_val = np.load(\"val_fused_labels_clean.npy\")\n",
    "\n",
    "# Optional: if your MLP has 1024 input, pad image/text features accordingly\n",
    "# assert X_train.shape[1] == 1024\n",
    "\n",
    "# Scale inputs\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_bal, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_bal, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)\n",
    "\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]  # or manually set to 256 for image-only\n",
    "model = MLPWithDropout(input_dim).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 10\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# ros = RandomOverSampler(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# ðŸ”¹ Evaluate on Training Set\n",
    "model.eval()\n",
    "y_train_preds = []\n",
    "y_train_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        out = model(xb)\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "        y_train_preds.extend(preds.cpu().numpy())\n",
    "        y_train_true.extend(yb.numpy())\n",
    "\n",
    "# Training Metrics\n",
    "train_acc = accuracy_score(y_train_true, y_train_preds)\n",
    "print(f\"ðŸ“Š Training Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "# ðŸ”¹ Evaluate on Validation Set\n",
    "model.eval()\n",
    "y_val_preds = []\n",
    "y_val_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in val_loader:\n",
    "        xb = xb.to(device)\n",
    "        out = model(xb)\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "        y_val_preds.extend(preds.cpu().numpy())\n",
    "        y_val_true.extend(yb.numpy())\n",
    "\n",
    "# Metrics\n",
    "val_acc = accuracy_score(y_val_true, y_val_preds)\n",
    "print(f\"âœ… Validation Accuracy: {val_acc:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_true, y_val_preds, target_names=[\"AD\", \"CN\", \"MCI\"]))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val_true, y_val_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Purples\", xticklabels=[\"AD\", \"CN\", \"MCI\"], yticklabels=[\"AD\", \"CN\", \"MCI\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix - MLP (Validation Set)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82e51e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy: 0.4935\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.39      0.47      0.42      1870\n",
      "          CN       0.46      0.39      0.42      2585\n",
      "         MCI       0.57      0.58      0.57      3960\n",
      "\n",
      "    accuracy                           0.49      8415\n",
      "   macro avg       0.47      0.48      0.47      8415\n",
      "weighted avg       0.50      0.49      0.49      8415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Assuming y_test and y_pred are already defined from your previous evaluation\n",
    "\n",
    "# Define class labels (you can update these if your label encoding is different)\n",
    "class_names = ['AD', 'CN', 'MCI']\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_val_true, y_val_preds)\n",
    "print(f\"\\n Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Precision, Recall, F1-score\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_val_true, y_val_preds, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f517f460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
